# Customer Churn Prediction

This project predicts customer churn using a machine learning pipeline. The pipeline is built using DVC and YAML configuration files. The model is trained using Random Forest Classifier and achieves 85% accuracy. The code includes logging for error tracking and hyperparameter tuning using GridSearchCV.

## Under Development
 So all feautres are not implemented yet

 
## Project Highlights

- Model: Random Forest Classifier  
- Pipeline: Built using DVC and YAML  
- Hyperparameter Tuning: Performed using GridSearchCV  
- Logging: Implemented with Python's logging module  
- Accuracy Achieved: 85% on test data  


## ğŸš€ Features

- ğŸ”„ **Data Version Control (DVC)**: Track and version datasets and ML models.
- ğŸ§¹ **Data Preprocessing**: Clean, transform, and split raw data.
- ğŸ§  **ML Modeling**: Train and evaluate predictive models.
- ğŸ“¦ **Model Registry**: Store and version trained models.
- ğŸ§ª **Testing Suite**: Unit tests for pipeline components.
- âš™ï¸ **CI/CD Integration**: GitHub Actions for linting, testing, and model training.
- â˜ï¸ **Cloud-ready**: Configurable for deployment on AWS, Azure, or GCP.

---

## ğŸ—‚ï¸ Project Structure

```

retainStack/
â”‚
â”œâ”€â”€ data/                      # Raw and processed datasets
â”œâ”€â”€ logger/
|   â”œâ”€â”€ logger.py              # Logger module for log monitoring
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ data_ingestion.py     # Ingestion scripts
â”‚   â”œâ”€â”€ preprocessing.py  # Cleaning and splitting logic
â”‚   â”œâ”€â”€ model.py            # Model Evaluation
â”‚   
â”‚  
â”œâ”€â”€ dvc.yaml                   # DVC pipeline definition
â”œâ”€â”€ params.yaml                # Hyperparameters & config
â”œâ”€â”€ .github/workflows/         # CI/CD workflows
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

````

---

## ğŸ“¦ Setup Instructions

1. **Clone the repo**
   ```bash
   git clone https://github.com/sakshinaithani2005/customer_churn_prediction
   cd RetainStack
    ```

2. **Create virtual environment**

   ```bash
   python -m venv .venv
   source .venv/bin/activate   # Linux/Mac
   .venv\Scripts\activate      # Windows
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Set up DVC**

   ```bash
   dvc init
   dvc pull
   ```

---

## âš™ï¸ Running the Pipeline

To run the full DVC pipeline:

```bash
dvc repro
```

To run individual stages (e.g., data ingestion):

```bash
python src/data_ingestion.py
```

---

## ğŸ“ Configuration

All configuration (paths, split ratios, model parameters) is defined in:

* `params.yaml` for hyperparameters
* `config.py` for directory structure
* `dvc.yaml` for pipeline stages

---


## ğŸ“Œ Future Improvements

* Streamlit or FastAPI serving
* MLflow for model tracking
* Full cloud deployment (SageMaker, Vertex AI)

---

## ğŸ‘¨â€ğŸ’» Author

**Sakshi**
---

